# .MessageApi

All URIs are relative to *http://localhost*

Method | HTTP request | Description
------------- | ------------- | -------------
[**createMessageCompletionHandler**](MessageApi.md#createMessageCompletionHandler) | **POST** /api/message | create_message
[**editMessageHandler**](MessageApi.md#editMessageHandler) | **PUT** /api/message | edit_message
[**getAllTopicMessages**](MessageApi.md#getAllTopicMessages) | **GET** /api/messages/{messages_topic_id} | get_all_messages
[**regenerateMessageHandler**](MessageApi.md#regenerateMessageHandler) | **DELETE** /api/message | regenerate_message


# **createMessageCompletionHandler**
> string createMessageCompletionHandler(createMessageData)

create_message  Create a message. Messages are attached to topics in order to coordinate memory of gen-AI chat sessions. We are considering refactoring this resource of the API soon. Currently, you can only send user messages. If the topic is a RAG topic then the response will include Chunks first on the stream. The structure will look like `[chunks]||mesage`. See docs.trieve.ai for more information.

### Example


```typescript
import {  } from '';
import * as fs from 'fs';

const configuration = .createConfiguration();
const apiInstance = new .MessageApi(configuration);

let body:.MessageApiCreateMessageCompletionHandlerRequest = {
  // string | The dataset id to use for the request
  tRDataset: "TR-Dataset_example",
  // CreateMessageData | JSON request payload to create a message completion
  createMessageData: {
    highlightCitations: true,
    highlightDelimiters: [
      "highlightDelimiters_example",
    ],
    model: "model_example",
    newMessageContent: "newMessageContent_example",
    streamResponse: true,
    topicId: "topicId_example",
  },
};

apiInstance.createMessageCompletionHandler(body).then((data:any) => {
  console.log('API called successfully. Returned data: ' + data);
}).catch((error:any) => console.error(error));
```


### Parameters

Name | Type | Description  | Notes
------------- | ------------- | ------------- | -------------
 **createMessageData** | **CreateMessageData**| JSON request payload to create a message completion |
 **tRDataset** | [**string**] | The dataset id to use for the request | defaults to undefined


### Return type

**string**

### Authorization

[Cookie](README.md#Cookie), [ApiKey](README.md#ApiKey)

### HTTP request headers

 - **Content-Type**: application/json
 - **Accept**: text/plain, application/json


### HTTP response details
| Status code | Description | Response headers |
|-------------|-------------|------------------|
**200** | This will be a JSON response of a string containing the LLM\&#39;s generated inference. Response if not streaming. |  -  |
**400** | Service error relating to getting a chat completion |  -  |

[[Back to top]](#) [[Back to API list]](README.md#documentation-for-api-endpoints) [[Back to Model list]](README.md#documentation-for-models) [[Back to README]](README.md)

# **editMessageHandler**
> void editMessageHandler(editMessageData)

edit_message  Edit a message which exists within the topic\'s chat history. This will delete the message and replace it with a new message. The new message will be generated by the AI based on the new content provided in the request body. The response will include Chunks first on the stream if the topic is using RAG. The structure will look like `[chunks]||mesage`. See docs.trieve.ai for more information.

### Example


```typescript
import {  } from '';
import * as fs from 'fs';

const configuration = .createConfiguration();
const apiInstance = new .MessageApi(configuration);

let body:.MessageApiEditMessageHandlerRequest = {
  // string | The dataset id to use for the request
  tRDataset: "TR-Dataset_example",
  // EditMessageData | JSON request payload to edit a message and get a new stream
  editMessageData: {
    highlightCitations: true,
    highlightDelimiters: [
      "highlightDelimiters_example",
    ],
    messageSortOrder: 1,
    model: "model_example",
    newMessageContent: "newMessageContent_example",
    streamResponse: true,
    topicId: "topicId_example",
  },
};

apiInstance.editMessageHandler(body).then((data:any) => {
  console.log('API called successfully. Returned data: ' + data);
}).catch((error:any) => console.error(error));
```


### Parameters

Name | Type | Description  | Notes
------------- | ------------- | ------------- | -------------
 **editMessageData** | **EditMessageData**| JSON request payload to edit a message and get a new stream |
 **tRDataset** | [**string**] | The dataset id to use for the request | defaults to undefined


### Return type

**void**

### Authorization

[Cookie](README.md#Cookie), [ApiKey](README.md#ApiKey)

### HTTP request headers

 - **Content-Type**: application/json
 - **Accept**: application/json


### HTTP response details
| Status code | Description | Response headers |
|-------------|-------------|------------------|
**200** | This will be a HTTP stream, check the chat or search UI for an example how to process this |  -  |
**400** | Service error relating to getting a chat completion |  -  |

[[Back to top]](#) [[Back to API list]](README.md#documentation-for-api-endpoints) [[Back to Model list]](README.md#documentation-for-models) [[Back to README]](README.md)

# **getAllTopicMessages**
> Array<Message> getAllTopicMessages()

get_all_messages  Get all messages for a given topic. If the topic is a RAG topic then the response will include Chunks first on each message. The structure will look like `[chunks]||mesage`. See docs.trieve.ai for more information.

### Example


```typescript
import {  } from '';
import * as fs from 'fs';

const configuration = .createConfiguration();
const apiInstance = new .MessageApi(configuration);

let body:.MessageApiGetAllTopicMessagesRequest = {
  // string | The ID of the topic to get messages for.
  messagesTopicId: "messages_topic_id_example",
  // string | The dataset id to use for the request
  tRDataset: "TR-Dataset_example",
};

apiInstance.getAllTopicMessages(body).then((data:any) => {
  console.log('API called successfully. Returned data: ' + data);
}).catch((error:any) => console.error(error));
```


### Parameters

Name | Type | Description  | Notes
------------- | ------------- | ------------- | -------------
 **messagesTopicId** | [**string**] | The ID of the topic to get messages for. | defaults to undefined
 **tRDataset** | [**string**] | The dataset id to use for the request | defaults to undefined


### Return type

**Array<Message>**

### Authorization

[Cookie](README.md#Cookie), [ApiKey](README.md#ApiKey)

### HTTP request headers

 - **Content-Type**: Not defined
 - **Accept**: application/json


### HTTP response details
| Status code | Description | Response headers |
|-------------|-------------|------------------|
**200** | All messages relating to the topic with the given ID |  -  |
**400** | Service error relating to getting the messages |  -  |

[[Back to top]](#) [[Back to API list]](README.md#documentation-for-api-endpoints) [[Back to Model list]](README.md#documentation-for-models) [[Back to README]](README.md)

# **regenerateMessageHandler**
> string regenerateMessageHandler(regenerateMessageData)

regenerate_message  Regenerate the assistant response to the last user message of a topic. This will delete the last message and replace it with a new message. The response will include Chunks first on the stream if the topic is using RAG. The structure will look like `[chunks]||mesage`. See docs.trieve.ai for more information.

### Example


```typescript
import {  } from '';
import * as fs from 'fs';

const configuration = .createConfiguration();
const apiInstance = new .MessageApi(configuration);

let body:.MessageApiRegenerateMessageHandlerRequest = {
  // string | The dataset id to use for the request
  tRDataset: "TR-Dataset_example",
  // RegenerateMessageData | JSON request payload to delete an agent message then regenerate it in a strem
  regenerateMessageData: {
    highlightCitations: true,
    highlightDelimiters: [
      "highlightDelimiters_example",
    ],
    model: "model_example",
    streamResponse: true,
    topicId: "topicId_example",
  },
};

apiInstance.regenerateMessageHandler(body).then((data:any) => {
  console.log('API called successfully. Returned data: ' + data);
}).catch((error:any) => console.error(error));
```


### Parameters

Name | Type | Description  | Notes
------------- | ------------- | ------------- | -------------
 **regenerateMessageData** | **RegenerateMessageData**| JSON request payload to delete an agent message then regenerate it in a strem |
 **tRDataset** | [**string**] | The dataset id to use for the request | defaults to undefined


### Return type

**string**

### Authorization

[Cookie](README.md#Cookie), [ApiKey](README.md#ApiKey)

### HTTP request headers

 - **Content-Type**: application/json
 - **Accept**: text/plain, application/json


### HTTP response details
| Status code | Description | Response headers |
|-------------|-------------|------------------|
**200** | This will be a JSON response of a string containing the LLM\&#39;s generated inference. Response if not streaming. |  -  |
**400** | Service error relating to getting a chat completion |  -  |

[[Back to top]](#) [[Back to API list]](README.md#documentation-for-api-endpoints) [[Back to Model list]](README.md#documentation-for-models) [[Back to README]](README.md)


